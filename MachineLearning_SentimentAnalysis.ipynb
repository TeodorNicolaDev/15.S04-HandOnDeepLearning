{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1XcUSnO6CZpg"
      },
      "source": [
        "# IMDb Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOxAgSFhCV5O"
      },
      "source": [
        "## Technical Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjqUzwe969mu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLjFZv7qFyiI"
      },
      "source": [
        "## Problem Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBtY6YPfFuzr"
      },
      "source": [
        "We will work with the famous IMDb dataset of movie reviews.\n",
        "\n",
        "The datasets we will work with has just two columns:\n",
        "* the text of the review\n",
        "* a label of 1 or 0 indicating a positive or negative review\n",
        "\n",
        "Our task is to develop models to predict the sentiment from the review text.\n",
        "\n",
        "As you will soon see, we only have 50 reviews in the training set! Given this small dataset, what's the best way to build an accurate model? That's what we will try to answer in this homework!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYaoGIaOpo2Z"
      },
      "source": [
        "## Data Prep\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHt704h9pAq_"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('https://www.dropbox.com/s/seqzwmzfpq50kyn/train_df.csv?dl=1', index_col=0)\n",
        "test_df = pd.read_csv('https://www.dropbox.com/s/dssjsrxr9zx43rq/test_df.csv?dl=1', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RK7K2ZCqTb4",
        "outputId": "14fd8585-3fab-4cfb-afd2-007024f4dc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train samples: 50\n",
            "Test samples: 500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"\n",
        "Train samples: {train_df.shape[0]}\n",
        "Test samples: {test_df.shape[0]}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wZtI-YRqTRrg",
        "outputId": "1a970e38-00ae-4271-be9e-08b51d809e35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4cbcf5cf-5d71-400a-8006-09266cb98605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7069</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"If derivative and predictable rape-revenge t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16664</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Unimaginably stupid, redundant and humiliati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3362</th>\n",
              "      <td>0</td>\n",
              "      <td>b'This is the kind of movie which shows the pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"This is by far THE WORST movie i have ever w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13898</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"What a load of rubbish.. I can't even begin ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cbcf5cf-5d71-400a-8006-09266cb98605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cbcf5cf-5d71-400a-8006-09266cb98605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cbcf5cf-5d71-400a-8006-09266cb98605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label                                               text\n",
              "7069       0  b\"If derivative and predictable rape-revenge t...\n",
              "16664      0  b'Unimaginably stupid, redundant and humiliati...\n",
              "3362       0  b'This is the kind of movie which shows the pa...\n",
              "165        0  b\"This is by far THE WORST movie i have ever w...\n",
              "13898      0  b\"What a load of rubbish.. I can't even begin ..."
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzLguIWdeB-5"
      },
      "source": [
        "What's the proportion of positive and negative labels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dVkRgPIuneP",
        "outputId": "b96b6dca-15af-4852-87e2-e06f928ed923"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.5\n",
              "1    0.5\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['label'].value_counts() / train_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUcvhXrWGEqp"
      },
      "source": [
        "Nice, it is balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sia5LebDeuDM"
      },
      "outputs": [],
      "source": [
        "# Let's turn the target into a dummy vector\n",
        "y_train = pd.get_dummies(train_df['label']).to_numpy()\n",
        "y_test = pd.get_dummies(test_df['label']).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkAbzy4IGNbH",
        "outputId": "754bbbb5-a223-4e1e-ab9b-ae187a53c546"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ktfnOWeX-x"
      },
      "source": [
        "## Problem 1: Bag-of-Words Baseline Model\n",
        "\n",
        "Please follow the instructions in the HW PDF and complete the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h48xnYwyXLWK"
      },
      "outputs": [],
      "source": [
        "# First, we configure a Text Vectorization layer using the default\n",
        "# standardization and multi-hot encoding\n",
        "\n",
        "# Set the maximum number of tokens\n",
        "max_tokens = 1000\n",
        "\n",
        "# Configure the text vectorization layer\n",
        "text_vectorization = keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"multi_hot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svlV4v_LXSx1"
      },
      "outputs": [],
      "source": [
        "# Let's adapt the Text Vectorization layer using the training corpus\n",
        "text_vectorization.adapt(train_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO96Ho9WXVtb"
      },
      "outputs": [],
      "source": [
        "# We vectorize our input with the adapted Text Vectorization layer\n",
        "x_train = text_vectorization(train_df['text'])\n",
        "x_test = text_vectorization(test_df['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEkv6OJZXauJ",
        "outputId": "7516e477-82b3-4508-a3eb-5753d86b0f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 8)                 8008      \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,026\n",
            "Trainable params: 8,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a baseline NN model with one hidden layer that has 8 neurons.\n",
        "\n",
        "inputs = keras.Input(shape=(max_tokens, ))\n",
        "x = keras.layers.Dense(8, activation=\"relu\")(inputs)\n",
        "outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCQixpe6gHmh",
        "outputId": "bf9e654a-cb28-4486-b223-61c71abab536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8026\n"
          ]
        }
      ],
      "source": [
        "num_param_dense = 8 * 1000 + 8   #8008\n",
        "output = 8*2 + 2                 #18\n",
        "total = num_param_dense + output\n",
        "print(total)                     #8026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxrum8-tp9Xc",
        "outputId": "a27a8b81-e914-41c4-c0ab-612222bad6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 18ms/step - loss: 0.7076 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6672 - accuracy: 0.6200\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6350 - accuracy: 0.6800\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6100 - accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5854 - accuracy: 0.8200\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5641 - accuracy: 0.8400\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5414 - accuracy: 0.8600\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5181 - accuracy: 0.8800\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.9000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.9200\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f92e5ac6ec0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile model using Adam\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model on the training data with 10 epochs and batch size of 32\n",
        "model.fit(x=x_train, y=y_train,\n",
        "          epochs=10,\n",
        "          batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6Hy7XwfXfL0",
        "outputId": "0040fe3f-32f0-42e0-c168-cbfbabea369d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.5900\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4539 - accuracy: 0.9200\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.453866571187973, 0.9200000166893005]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Accuracy on test data\n",
        "model.evaluate(x=x_test, y=y_test)\n",
        "model.evaluate(x=x_train, y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlSWRoTGqn7Y"
      },
      "source": [
        "## Problem 2: Improve the baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2zmxTRquGw"
      },
      "source": [
        "In this problem, we will define and train more complex models to try to increase the accuracy on our test dataset. Try combining different models by changing:\n",
        "- Number of hidden units\n",
        "- Adding another hidden layer.\n",
        "- Adding dropout.\n",
        "- Changing the number of epochs.\n",
        "- Using bigrams instead of unigrams.\n",
        "\n",
        "To guide your search for the best parameters, note how the accuracy changes on both train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72tQJQOWqrxG",
        "outputId": "032a14f8-9c57-4ed7-c371-7d45017b3466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 8)                 8008      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,026\n",
            "Trainable params: 8,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 0.7233 - accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7017 - accuracy: 0.4400\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.5200\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6572 - accuracy: 0.5800\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.7400\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5745 - accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5619 - accuracy: 0.7600\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5855 - accuracy: 0.7400\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5423 - accuracy: 0.7600\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5385 - accuracy: 0.7200\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5400\n",
            "Model: \"model_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_28 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 8)                 8008      \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,098\n",
            "Trainable params: 8,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 0.8220 - accuracy: 0.4600\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7094 - accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7016 - accuracy: 0.4800\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.4600\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6240 - accuracy: 0.6600\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6246 - accuracy: 0.6400\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.6600\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6151 - accuracy: 0.6600\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5864 - accuracy: 0.7400\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5776 - accuracy: 0.8200\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5400\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  10  Test Accuracy of the model =  0.5400000214576721\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4938 - accuracy: 0.9600\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  10  Train Accuracy of the model =  0.9599999785423279\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4938 - accuracy: 0.9600\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5400\n",
            "Delta = 0.41999995708465576\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5140\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  10  Test Accuracy of the model =  0.5139999985694885\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5620 - accuracy: 0.7400\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  10  Train Accuracy of the model =  0.7400000095367432\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.7400\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5140\n",
            "Delta = 0.22600001096725464\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.9600\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4938 - accuracy: 0.9600\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5400\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5140\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.7400\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.7400\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5140\n",
            "Model: \"model_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_29 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 16)                16016     \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,050\n",
            "Trainable params: 16,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 0.6726 - accuracy: 0.5600\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6316 - accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5729 - accuracy: 0.7200\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5436 - accuracy: 0.7200\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5939 - accuracy: 0.7200\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4886 - accuracy: 0.7800\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4298 - accuracy: 0.8400\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4277 - accuracy: 0.8800\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8800\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4406 - accuracy: 0.8000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5700\n",
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_30 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 16)                16016     \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,322\n",
            "Trainable params: 16,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 0.6792 - accuracy: 0.5400\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6615 - accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6484 - accuracy: 0.5600\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.6800\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6050 - accuracy: 0.6600\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5738 - accuracy: 0.7000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5460 - accuracy: 0.7000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5541 - accuracy: 0.7000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5117 - accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5282 - accuracy: 0.7400\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5700\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  10  Test Accuracy of the model =  0.5699999928474426\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3249 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5700\n",
            "Delta = 0.4300000071525574\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6984 - accuracy: 0.5340\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  10  Test Accuracy of the model =  0.5339999794960022\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.9800\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  10  Train Accuracy of the model =  0.9800000190734863\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4652 - accuracy: 0.9800\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6984 - accuracy: 0.5340\n",
            "Delta = 0.44600003957748413\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6748 - accuracy: 0.5700\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3249 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3249 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.5700\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.5340\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4652 - accuracy: 0.9800\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4652 - accuracy: 0.9800\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.5340\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_31 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 32)                32032     \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,098\n",
            "Trainable params: 32,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 16ms/step - loss: 0.9044 - accuracy: 0.5200\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7034 - accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5800\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6502 - accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5479 - accuracy: 0.7600\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5162 - accuracy: 0.7400\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4877 - accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4333 - accuracy: 0.8600\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4337 - accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3995 - accuracy: 0.9000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.5860\n",
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_32 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 32)                32032     \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,154\n",
            "Trainable params: 33,154\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 0.7054 - accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6985 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6563 - accuracy: 0.5600\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5610 - accuracy: 0.7600\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.8400\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4815 - accuracy: 0.8400\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4549 - accuracy: 0.8200\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.8600\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4552 - accuracy: 0.8200\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5860\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  10  Test Accuracy of the model =  0.5860000252723694\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3027 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3027 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5860\n",
            "Delta = 0.4139999747276306\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5500\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  10  Test Accuracy of the model =  0.550000011920929\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3653 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5500\n",
            "Delta = 0.44999998807907104\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5860\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3027 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5860\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3653 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3653 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5500\n",
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_33 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,194\n",
            "Trainable params: 64,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 0.7902 - accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5818 - accuracy: 0.7000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3732 - accuracy: 0.9200\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3662 - accuracy: 0.9400\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3083 - accuracy: 0.9200\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2652 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2060 - accuracy: 0.9600\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6160\n",
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_34 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 64)                64064     \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,354\n",
            "Trainable params: 68,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 0.7357 - accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5783 - accuracy: 0.7200\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5342 - accuracy: 0.8200\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4807 - accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.9600\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3040 - accuracy: 0.9600\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2956 - accuracy: 0.9400\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2335 - accuracy: 0.9600\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6160\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  10  Test Accuracy of the model =  0.6159999966621399\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1844 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1844 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6160\n",
            "Delta = 0.3840000033378601\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.6560\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  10  Test Accuracy of the model =  0.656000018119812\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1384 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6560\n",
            "Delta = 0.343999981880188\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6160\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1844 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1844 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6160\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6560\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1384 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6328 - accuracy: 0.6560\n",
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_35 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 128)               128128    \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 128,386\n",
            "Trainable params: 128,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 12ms/step - loss: 0.8128 - accuracy: 0.4800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6448 - accuracy: 0.5600\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4679 - accuracy: 0.8200\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3807 - accuracy: 0.9000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3076 - accuracy: 0.9600\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2372 - accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2321 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1603 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1441 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1284 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6420\n",
            "Model: \"model_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_36 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 128)               128128    \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 144,898\n",
            "Trainable params: 144,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 21ms/step - loss: 0.7527 - accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5846 - accuracy: 0.7400\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4756 - accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4260 - accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3395 - accuracy: 0.9200\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2887 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2212 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2006 - accuracy: 0.9800\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1367 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1220 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6420\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  10  Test Accuracy of the model =  0.6420000195503235\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0959 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6420\n",
            "Delta = 0.3579999804496765\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6780\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  10  Test Accuracy of the model =  0.6779999732971191\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6780\n",
            "Delta = 0.32200002670288086\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6420\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0959 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0959 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6420\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6780\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6780\n",
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_37 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 256)               256256    \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,770\n",
            "Trainable params: 256,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 16ms/step - loss: 0.7775 - accuracy: 0.3800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5346 - accuracy: 0.7800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3463 - accuracy: 0.9600\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2845 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2347 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1888 - accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1111 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0840 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6860\n",
            "Model: \"model_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_38 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 256)               256256    \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,562\n",
            "Trainable params: 322,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 18ms/step - loss: 0.7459 - accuracy: 0.4600\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5161 - accuracy: 0.7800\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3624 - accuracy: 0.9200\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3065 - accuracy: 0.9400\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1814 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1186 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9800\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0388 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6860\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  10  Test Accuracy of the model =  0.6859999895095825\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6860\n",
            "Delta = 0.3140000104904175\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6920\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  10  Test Accuracy of the model =  0.6919999718666077\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  10  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6920\n",
            "Delta = 0.30800002813339233\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6860\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.6860\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6920\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6920\n",
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_39 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 8)                 8008      \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,026\n",
            "Trainable params: 8,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 9ms/step - loss: 0.7559 - accuracy: 0.4400\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7454 - accuracy: 0.5400\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.4600\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.4400\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6476 - accuracy: 0.6200\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6367 - accuracy: 0.5800\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5590 - accuracy: 0.7600\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5503 - accuracy: 0.7800\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.7200\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5506 - accuracy: 0.7000\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5958 - accuracy: 0.6000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5449 - accuracy: 0.7400\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5014 - accuracy: 0.7600\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4792 - accuracy: 0.7600\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4515 - accuracy: 0.8000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4045 - accuracy: 0.8800\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.8200\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4132 - accuracy: 0.8000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4050 - accuracy: 0.8600\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.4218 - accuracy: 0.8800\n",
            "16/16 [==============================] - 1s 3ms/step - loss: 0.6722 - accuracy: 0.5760\n",
            "Model: \"model_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_40 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 8)                 8008      \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,098\n",
            "Trainable params: 8,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 0.6799 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6559 - accuracy: 0.7000\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6478 - accuracy: 0.6800\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6474 - accuracy: 0.6400\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6722 - accuracy: 0.6200\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6196 - accuracy: 0.6600\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6437 - accuracy: 0.6000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6271 - accuracy: 0.5400\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5990 - accuracy: 0.7200\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5863 - accuracy: 0.7600\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5762 - accuracy: 0.7200\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6533 - accuracy: 0.6000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5896 - accuracy: 0.6600\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5477 - accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5201 - accuracy: 0.7800\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5493 - accuracy: 0.7400\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5795 - accuracy: 0.7800\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5064 - accuracy: 0.8400\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4947 - accuracy: 0.8800\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5840 - accuracy: 0.6600\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5760\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  20  Test Accuracy of the model =  0.5759999752044678\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3178 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3178 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.5760\n",
            "Delta = 0.4240000247955322\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5220\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  20  Test Accuracy of the model =  0.5220000147819519\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.9400\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  8 ;no_epochs =  20  Train Accuracy of the model =  0.9399999976158142\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.9400\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5220\n",
            "Delta = 0.4179999828338623\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.5760\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.5760\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5220\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.9400\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.9400\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.5220\n",
            "Model: \"model_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_41 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 16)                16016     \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,050\n",
            "Trainable params: 16,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 0.7200 - accuracy: 0.4800\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.5800\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5708 - accuracy: 0.7200\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6416 - accuracy: 0.6600\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5392 - accuracy: 0.8200\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5369 - accuracy: 0.8400\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5150 - accuracy: 0.7600\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4951 - accuracy: 0.8200\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4936 - accuracy: 0.7400\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8600\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.8200\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3824 - accuracy: 0.9200\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4037 - accuracy: 0.9000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3926 - accuracy: 0.9200\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3679 - accuracy: 0.8800\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3172 - accuracy: 0.9400\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3457 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2833 - accuracy: 0.9600\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3142 - accuracy: 0.9200\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3148 - accuracy: 0.9400\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6020\n",
            "Model: \"model_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_42 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 16)                16016     \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,322\n",
            "Trainable params: 16,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 14ms/step - loss: 0.7206 - accuracy: 0.6000\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7020 - accuracy: 0.6000\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 0.6000\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6059 - accuracy: 0.7600\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5678 - accuracy: 0.6400\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5220 - accuracy: 0.7800\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4795 - accuracy: 0.8400\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4981 - accuracy: 0.7600\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4179 - accuracy: 0.9000\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.8400\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4355 - accuracy: 0.8400\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.3684 - accuracy: 0.9000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3726 - accuracy: 0.8800\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3770 - accuracy: 0.8400\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3394 - accuracy: 0.8800\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3552 - accuracy: 0.8800\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3060 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2729 - accuracy: 0.9400\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2744 - accuracy: 0.9200\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2411 - accuracy: 0.8800\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6020\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  20  Test Accuracy of the model =  0.6019999980926514\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2031 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2031 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6020\n",
            "Delta = 0.39800000190734863\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6400\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  20  Test Accuracy of the model =  0.6399999856948853\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1819 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  16 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1819 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6400\n",
            "Delta = 0.36000001430511475\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6020\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2031 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6020\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6400\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1819 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6400\n",
            "Model: \"model_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_43 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 32)                32032     \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,098\n",
            "Trainable params: 32,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 12ms/step - loss: 0.8467 - accuracy: 0.4400\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6060 - accuracy: 0.6600\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5600 - accuracy: 0.6800\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5410 - accuracy: 0.7200\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4934 - accuracy: 0.7800\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4103 - accuracy: 0.8800\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 0.9000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3379 - accuracy: 0.9400\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3000 - accuracy: 0.9600\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2842 - accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2446 - accuracy: 0.9800\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2532 - accuracy: 0.9400\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2123 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2028 - accuracy: 0.9800\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1537 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2199 - accuracy: 0.9400\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1615 - accuracy: 0.9800\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1359 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6340\n",
            "Model: \"model_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_44 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 32)                32032     \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,154\n",
            "Trainable params: 33,154\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 14ms/step - loss: 0.7378 - accuracy: 0.4600\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6469 - accuracy: 0.6400\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5886 - accuracy: 0.7200\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5878 - accuracy: 0.7200\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5447 - accuracy: 0.7600\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4962 - accuracy: 0.8400\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4723 - accuracy: 0.9000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4326 - accuracy: 0.9000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3458 - accuracy: 0.9200\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4236 - accuracy: 0.8600\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3737 - accuracy: 0.9000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3282 - accuracy: 0.9000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3357 - accuracy: 0.9000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2619 - accuracy: 0.9600\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2954 - accuracy: 0.8800\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.2102 - accuracy: 0.9600\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1815 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2142 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1861 - accuracy: 0.9800\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.9400\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6340\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  20  Test Accuracy of the model =  0.6340000033378601\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0848 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6340\n",
            "Delta = 0.3659999966621399\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6560\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  20  Test Accuracy of the model =  0.656000018119812\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  32 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6560\n",
            "Delta = 0.343999981880188\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6340\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0848 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6340\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6560\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1023 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1023 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6560\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_45 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,194\n",
            "Trainable params: 64,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 14ms/step - loss: 0.8462 - accuracy: 0.4600\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6597 - accuracy: 0.6200\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.5603 - accuracy: 0.7600\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4854 - accuracy: 0.7600\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4317 - accuracy: 0.8000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3701 - accuracy: 0.8400\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.3360 - accuracy: 0.9400\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2820 - accuracy: 0.9400\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2381 - accuracy: 0.9800\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1959 - accuracy: 0.9800\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1915 - accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1579 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1491 - accuracy: 0.9800\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1102 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0951 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1043 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0723 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0764 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6600\n",
            "Model: \"model_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_46 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 64)                64064     \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,354\n",
            "Trainable params: 68,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 18ms/step - loss: 0.7934 - accuracy: 0.4600\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6925 - accuracy: 0.5600\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.7400\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5623 - accuracy: 0.7200\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4622 - accuracy: 0.8800\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4514 - accuracy: 0.8600\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3797 - accuracy: 0.9400\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.9400\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2857 - accuracy: 0.9800\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2696 - accuracy: 0.9400\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9600\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2314 - accuracy: 0.9800\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1941 - accuracy: 0.9800\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1434 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1235 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1116 - accuracy: 0.9800\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1116 - accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9800\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6600\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  20  Test Accuracy of the model =  0.6600000262260437\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6600\n",
            "Delta = 0.3399999737739563\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6800\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  20  Test Accuracy of the model =  0.6800000071525574\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  64 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6800\n",
            "Delta = 0.3199999928474426\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6600\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6600\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6800\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6800\n",
            "Model: \"model_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_47 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 128)               128128    \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 128,386\n",
            "Trainable params: 128,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 18ms/step - loss: 0.7966 - accuracy: 0.5200\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.5995 - accuracy: 0.6800\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4645 - accuracy: 0.8400\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3377 - accuracy: 0.9400\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2630 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.2394 - accuracy: 0.9600\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1387 - accuracy: 0.9800\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1463 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1008 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0860 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0546 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0532 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6660\n",
            "Model: \"model_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_48 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 128)               128128    \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 144,898\n",
            "Trainable params: 144,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 15ms/step - loss: 0.6731 - accuracy: 0.5400\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.5436 - accuracy: 0.8000\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4369 - accuracy: 0.9200\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.3393 - accuracy: 0.9600\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3155 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2063 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1809 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.1331 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1351 - accuracy: 0.9800\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0843 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6660\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  20  Test Accuracy of the model =  0.6660000085830688\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.6660\n",
            "Delta = 0.33399999141693115\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.6660\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  20  Test Accuracy of the model =  0.6660000085830688\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  128 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.6660\n",
            "Delta = 0.33399999141693115\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6660\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.6660\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.6660\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.6660\n",
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_49 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 256)               256256    \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,770\n",
            "Trainable params: 256,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 14ms/step - loss: 0.7425 - accuracy: 0.5400\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5477 - accuracy: 0.7800\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.8000\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3530 - accuracy: 0.8800\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1936 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.1591 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0964 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0710 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0594 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6920\n",
            "Model: \"model_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_50 (InputLayer)       [(None, 1000)]            0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 256)               256256    \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,562\n",
            "Trainable params: 322,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 18ms/step - loss: 0.7551 - accuracy: 0.3800\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4948 - accuracy: 0.8600\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.3713 - accuracy: 0.9400\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2605 - accuracy: 0.9800\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.1973 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.1222 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0738 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0556 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6920\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  20  Test Accuracy of the model =  0.6919999718666077\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Accuracy for the one hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6920\n",
            "Delta = 0.30800002813339233\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.6880\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  20  Test Accuracy of the model =  0.6880000233650208\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6.1454e-04 - accuracy: 1.0000\n",
            "Accuracy for the two hiden layer, with parameters: max_token_number = 1000 ; neuron_number =  256 ;no_epochs =  20  Train Accuracy of the model =  1.0\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.1454e-04 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.6880\n",
            "Delta = 0.31199997663497925\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6920\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6920\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7217 - accuracy: 0.6880\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.1454e-04 - accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1454e-04 - accuracy: 1.0000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7217 - accuracy: 0.6880\n",
            "{'Hidden units': [8, 8, 16, 16, 32, 32, 64, 64, 128, 128, 256, 256, 8, 8, 16, 16, 32, 32, 64, 64, 128, 128, 256, 256], 'Epochs': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], 'Hidden Layers': [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], 'Test accuracy': [0.5400000214576721, 0.5139999985694885, 0.5699999928474426, 0.5339999794960022, 0.5860000252723694, 0.550000011920929, 0.6159999966621399, 0.656000018119812, 0.6420000195503235, 0.6779999732971191, 0.6859999895095825, 0.6919999718666077, 0.5759999752044678, 0.5220000147819519, 0.6019999980926514, 0.6399999856948853, 0.6340000033378601, 0.656000018119812, 0.6600000262260437, 0.6800000071525574, 0.6660000085830688, 0.6660000085830688, 0.6919999718666077, 0.6880000233650208], 'Train Accuracy': [0.9599999785423279, 0.7400000095367432, 1.0, 0.9800000190734863, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9399999976158142, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'Delta Accuracy': [0.41999995708465576, 0.22600001096725464, 0.4300000071525574, 0.44600003957748413, 0.4139999747276306, 0.44999998807907104, 0.3840000033378601, 0.343999981880188, 0.3579999804496765, 0.32200002670288086, 0.3140000104904175, 0.30800002813339233, 0.4240000247955322, 0.4179999828338623, 0.39800000190734863, 0.36000001430511475, 0.3659999966621399, 0.343999981880188, 0.3399999737739563, 0.3199999928474426, 0.33399999141693115, 0.33399999141693115, 0.30800002813339233, 0.31199997663497925]}\n"
          ]
        }
      ],
      "source": [
        "# Begin your code here\n",
        "max_token_number = 1000\n",
        "\n",
        "# Multiple iterations with different number of neurons and epochs\n",
        "params = [[8,10],\n",
        "          [16,10],\n",
        "          [32,10],\n",
        "          [64,10],\n",
        "          [128,10],\n",
        "          [256,10],\n",
        "          [8,20],\n",
        "          [16,20],\n",
        "          [32,20],\n",
        "          [64,20],\n",
        "          [128,20],\n",
        "          [256,20]]\n",
        "\n",
        "results_dict = {'Hidden units'   :[],\n",
        "                'Epochs'         :[],\n",
        "                'Hidden Layers'  :[],\n",
        "                'Test accuracy'  :[],\n",
        "                'Train Accuracy' :[],\n",
        "                'Delta Accuracy' :[]\n",
        "                }\n",
        "\n",
        "for p in params:\n",
        "  neuron_number = p[0]\n",
        "  no_epochs = p[1]\n",
        "\n",
        "  text_vectorization = keras.layers.TextVectorization(\n",
        "      ngrams=2,\n",
        "      max_tokens=max_token_number,\n",
        "      output_mode=\"multi_hot\",\n",
        "  )\n",
        "\n",
        "  text_vectorization.adapt(train_df['text'])\n",
        "  x_train = text_vectorization(train_df['text'])\n",
        "  x_test = text_vectorization(test_df['text'])\n",
        "\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = keras.layers.Dense(neuron_number, activation=\"relu\")(inputs)\n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "  outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "  modelOneHidden = keras.Model(inputs, outputs)\n",
        "  modelOneHidden.summary()\n",
        "  modelOneHidden.compile(optimizer=\"adam\",\n",
        "                        loss=\"categorical_crossentropy\",\n",
        "                        metrics=[\"accuracy\"])\n",
        "\n",
        "  modelOneHidden.fit(x=x_train, y=y_train,\n",
        "            epochs=no_epochs,\n",
        "            batch_size=32)\n",
        "\n",
        "  modelOneHidden.evaluate(x=x_test, y=y_test)\n",
        "\n",
        "  #----------------------------------------------------------\n",
        "\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = keras.layers.Dense(neuron_number, activation=\"relu\")(inputs)\n",
        "  x = keras.layers.Dense(neuron_number, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "  outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "  modelTwoHidden = keras.Model(inputs, outputs)\n",
        "  modelTwoHidden.summary()\n",
        "  modelTwoHidden.compile(optimizer=\"adam\",\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  modelTwoHidden.fit(x=x_train, y=y_train,\n",
        "            epochs=no_epochs,\n",
        "            batch_size=32)\n",
        "\n",
        "  print(\"Accuracy for the one hiden layer, with parameters: max_token_number =\", max_token_number, \"; neuron_number = \", neuron_number, \";no_epochs = \", no_epochs,\" Test Accuracy of the model = \", modelOneHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "  print(\"Accuracy for the one hiden layer, with parameters: max_token_number =\", max_token_number, \"; neuron_number = \", neuron_number, \";no_epochs = \", no_epochs,\" Train Accuracy of the model = \", modelOneHidden.evaluate(x=x_train, y=y_train)[1])\n",
        "  print(\"Delta =\", modelOneHidden.evaluate(x=x_train, y=y_train)[1] - modelOneHidden.evaluate(x=x_test, y=y_test)[1] )\n",
        "  print(\"Accuracy for the two hiden layer, with parameters: max_token_number =\", max_token_number, \"; neuron_number = \", neuron_number, \";no_epochs = \", no_epochs,\" Test Accuracy of the model = \", modelTwoHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "  print(\"Accuracy for the two hiden layer, with parameters: max_token_number =\", max_token_number, \"; neuron_number = \", neuron_number, \";no_epochs = \", no_epochs,\" Train Accuracy of the model = \", modelTwoHidden.evaluate(x=x_train, y=y_train)[1])\n",
        "  print(\"Delta =\", modelTwoHidden.evaluate(x=x_train, y=y_train)[1] - modelTwoHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "\n",
        "\n",
        "  results_dict['Hidden units'].append(neuron_number)\n",
        "  results_dict['Epochs'].append(no_epochs)\n",
        "  results_dict['Hidden Layers'].append(1)\n",
        "  results_dict['Test accuracy'].append(modelOneHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "  results_dict['Train Accuracy'].append(modelOneHidden.evaluate(x=x_train, y=y_train)[1])\n",
        "  results_dict['Delta Accuracy'].append(modelOneHidden.evaluate(x=x_train, y=y_train)[1] - modelOneHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "\n",
        "  results_dict['Hidden units'].append(neuron_number)\n",
        "  results_dict['Epochs'].append(no_epochs)\n",
        "  results_dict['Hidden Layers'].append(2)\n",
        "  results_dict['Test accuracy'].append(modelTwoHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "  results_dict['Train Accuracy'].append(modelTwoHidden.evaluate(x=x_train, y=y_train)[1])\n",
        "  results_dict['Delta Accuracy'].append(modelTwoHidden.evaluate(x=x_train, y=y_train)[1] - modelTwoHidden.evaluate(x=x_test, y=y_test)[1])\n",
        "\n",
        "print(results_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_3-3fVA_QrZ"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame.from_dict(results_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cbkxEs6iA8Kl",
        "outputId": "f7eb928d-30da-4be7-97f7-bb4abc203364"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f0e660b7-4e56-4b09-a3d3-ac4aac5d9abb\", \"Model_Results.csv\", 1352)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "results_df.to_csv('Model_Results.csv', index = False, encoding = 'utf-8-sig')\n",
        "files.download('Model_Results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxHhlOZJ0bSE"
      },
      "source": [
        "## Problem 3: Use a pre-trained model\n",
        "\n",
        "Next, we use will a famous pre-trained model called [Bert](https://en.wikipedia.org/wiki/BERT_(language_model))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRx2DCmhw-qk",
        "outputId": "f551438a-6b50-40d3-d65f-892c8814603f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/6.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U tensorflow-text ## install the package for NLP tasks in tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAr0pFQX95Ll"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "\n",
        "bert_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "bert_layers = 12\n",
        "bert_units = 768\n",
        "bert_heads = 12\n",
        "\n",
        "bert_encoder = f'https://tfhub.dev/tensorflow/bert_en_uncased_L-{bert_layers}_H-{bert_units}_A-{bert_heads}/4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY_hRuGdCxOM"
      },
      "source": [
        "Let's look to some examples of the text processing required for BERT:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ode0elY3-OCs",
        "outputId": "78b15ccb-9d8f-40e2-be4f-7dd4eb3ca519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Ids   : [[  101  2023  2003  4038  2004  2009  2320  2001  1998 13599  2023  2007\n",
            "   1996  2048 12661  2015  1012   102     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "Word Ids   : [[  101  2348  1045  6758  2023  3185  1037  1016  2005  4760  1037  3143\n",
            "   3768  1997  3947  1999  2667  2000  3443  1037  3737  5469  2143  2009\n",
            "   2001  1037  2184  2006  1996  4895 18447  4765 19301  6057  4094  1012\n",
            "    102     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "bert_preprocess_model = hub.KerasLayer(bert_preprocess)\n",
        "\n",
        "text_test = ['This is comedy as it once was and comparing this with the two remakes.']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"]}')\n",
        "\n",
        "text_test = ['Although I rated this movie a 2 for showing a complete lack of effort in trying to create a quality horror film it was a 10 on the unintentional funny scale.']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OufVekDVDK0T"
      },
      "source": [
        "Notice how all examples start with the token `101` and end with `102` (and then followed by `[PAD]` tokens as indicated by 0). Those are special placeholder tokens that can be used for different purposes. For this exercise, we will only concern about the first one, and we will call this token the 'classification token', or `[CLS]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgG8s0O91o66"
      },
      "outputs": [],
      "source": [
        "max_length = 512\n",
        "preprocessor = hub.load(bert_preprocess)\n",
        "encoder = hub.KerasLayer(bert_encoder, trainable=False)\n",
        "\n",
        "def bert_textvect(x):\n",
        "  input = keras.layers.Input(shape=(), dtype=tf.string)\n",
        "  tokenized_input = hub.KerasLayer(preprocessor.tokenize)(input)\n",
        "  bert_pack_inputs = hub.KerasLayer(preprocessor.bert_pack_inputs, arguments=dict(seq_length=max_length))\n",
        "  output = bert_pack_inputs([tokenized_input])\n",
        "  model = keras.Model(input, output)\n",
        "  result = model.predict(x)\n",
        "  return result\n",
        "\n",
        "def bert_features(x):\n",
        "  inputs = dict(\n",
        "    input_word_ids=keras.layers.Input(shape=(max_length,), dtype=tf.int32),\n",
        "    input_mask=keras.layers.Input(shape=(max_length,), dtype=tf.int32),\n",
        "    input_type_ids=keras.layers.Input(shape=(max_length,), dtype=tf.int32),\n",
        "  )\n",
        "\n",
        "  output = encoder(inputs)['sequence_output'][:, 0, :]\n",
        "  model = keras.Model(inputs, output)\n",
        "  return model.predict(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T1OmMa9LJY1",
        "outputId": "06e4e863-fbeb-4b1e-f99f-dfefea2eac0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 73ms/step\n",
            "7069     b\"If derivative and predictable rape-revenge t...\n",
            "16664    b'Unimaginably stupid, redundant and humiliati...\n",
            "3362     b'This is the kind of movie which shows the pa...\n",
            "165      b\"This is by far THE WORST movie i have ever w...\n",
            "13898    b\"What a load of rubbish.. I can't even begin ...\n",
            "16719    b\"Bob Clampett's 'Porky's Poor Fish' is a so-s...\n",
            "9417     b'I loved the first \"Azumi\" movie. I\\'ve seen ...\n",
            "13277    b'This TV-made thriller is all talk, little ac...\n",
            "8861     b'Hi folks<br /><br />Forget about that movie....\n",
            "3330     b'I gave this more than a 1 because I did thin...\n",
            "1321     b\"An OK flick, set in Mexico, about a hit-man ...\n",
            "10135    b\"This movie wasn't awful but it wasn't very g...\n",
            "3518     b\"After coming off the first one you think the...\n",
            "1504     b\"<br /><br />I didn't see They Call Me Trinit...\n",
            "17526    b'I wished I\\'d taped MEN IN WHITE so I could ...\n",
            "5392     b'This is a fascinating film--especially to ol...\n",
            "3141     b'Warning! Spoilers!<br /><br />This is your t...\n",
            "9571     b\"I first saw this movie when I was about 10 y...\n",
            "8191     b'This movie tells the tender tale of a dement...\n",
            "14240    b'Watching this stinker constitutes cruel and ...\n",
            "5562     b\"this movie offers nothing but the dumbest co...\n",
            "12287    b\"Can A-Pix ever, ever, ever do anything right...\n",
            "8883     b\"Recap: Ron is about to marry Mel. They are d...\n",
            "5346     b'\"Nada\" was the most inadequate follow-up to ...\n",
            "2715     b\"Billy Crystal co-wrote, co-produced and star...\n",
            "1342     b'This movie blows you off your feet. This deb...\n",
            "3753     b\"Saw this a couple times on the Sundance Chan...\n",
            "18520    b'Val Kilmer and Dylan McDermott are terrific....\n",
            "216      b\"I have watched this movie well over 100-200 ...\n",
            "846      b\"The Cure is an amazing film...So suspenseful...\n",
            "79       b\"I have read over 100 of the Nancy Drew books...\n",
            "4928     b\"If you have any sort of appreciation for cha...\n",
            "18718    b'Of course, the story line for this movie isn...\n",
            "14017    b'Liked Stanley & Iris very much. Acting was v...\n",
            "8997     b'The short that starts this film is the true ...\n",
            "15773    b\"Along with Darkwing Duck this is unfairly ca...\n",
            "3145     b'I love Paul McCartney. He is, in my oppinion...\n",
            "4544     b\"I can honestly say I never expected this mov...\n",
            "6601     b'I was lucky to see \"Oliver!\" in 1968 on a bi...\n",
            "10140    b\"This was fun to watch, spookily atmospheric ...\n",
            "19863    b\"Fire And Ice is an animated film set in a fa...\n",
            "3715     b\"C'mon people, look at the title! LOL! I reme...\n",
            "74       b'The Three Stooges has always been some of th...\n",
            "11769    b'I would not hesitate to put this adaptation ...\n",
            "12814    b\"I cried my heart out, watching this movie. I...\n",
            "7566     b'\"A Family Affair\" takes us back to a less co...\n",
            "19586    b'I must have been only 11 when Mr Peepers sta...\n",
            "13492    b'This film could be one of the most underrate...\n",
            "3350     b\"<br /><br />I just bought this movie on DVD ...\n",
            "3307     b'Fairly funny Jim Carrey vehicle that has him...\n",
            "Name: text, dtype: object\n",
            "16/16 [==============================] - 1s 66ms/step\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "16/16 [==============================] - 21s 1s/step\n"
          ]
        }
      ],
      "source": [
        "X_bert_train = bert_textvect(train_df['text'])\n",
        "X_bert_test = bert_textvect(test_df['text'])\n",
        "\n",
        "features_train = bert_features(X_bert_train)\n",
        "features_test = bert_features(X_bert_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U27NRtVOBZCm"
      },
      "source": [
        "Next, we'll use the BERT output embedding for the CLS token as input to train a simple neural net.\n",
        "\n",
        "(BTW, we have commented out the `Dropout` layer - feel free to turn it on and see if it improves the model's accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC_1nO6LBYGW",
        "outputId": "34b1ccf3-c044-4ee0-c75b-f6241948a113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_31 (InputLayer)       [(None, 768)]             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                49216     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,506\n",
            "Trainable params: 53,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 0.9726 - accuracy: 0.4200\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5485 - accuracy: 0.7600\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8346 - accuracy: 0.5400\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5652 - accuracy: 0.6800\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5266 - accuracy: 0.6800\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.7800\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.3957 - accuracy: 0.8800\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3572 - accuracy: 0.8600\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3347 - accuracy: 0.8600\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2740 - accuracy: 0.9400\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.2672 - accuracy: 0.9000\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.2144 - accuracy: 0.9800\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.2211 - accuracy: 0.9200\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2120 - accuracy: 0.9400\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1987 - accuracy: 0.9400\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1432 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1529 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1359 - accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.1076 - accuracy: 0.9800\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.1089 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f180422b8b0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden_units = 64\n",
        "\n",
        "# Input\n",
        "input = keras.Input(shape=(bert_units, ))\n",
        "\n",
        "\n",
        "x = keras.layers.Dense(hidden_units)(input)\n",
        "x = keras.layers.Dense(hidden_units)(x)\n",
        "x = keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "output = keras.layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = keras.Model(input, output)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "# Fit model\n",
        "model.fit(x=features_train, y=y_train,\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1xOFbOqTox2",
        "outputId": "8749ed98-c94d-42f1-bfd6-f0416d1bec11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.7320\n",
            "[0.6586838960647583, 0.7319999933242798]\n"
          ]
        }
      ],
      "source": [
        "print(model.evaluate(features_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4MhbdNp4LPH",
        "outputId": "81069b20-e23a-458d-aa04-5b3376d936d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 210ms/step\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.01647703, 0.98352295]], dtype=float32)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review_text = ''' I found 'A Beautiful Mind' to be a captivating and thought-provoking film that offers\n",
        "                  a unique perspective on mental illness and the human experience. The film's nuanced portrayal\n",
        "                   of the complexities of the mind and its impact on relationships is both powerful and poignant.\n",
        "                   Russell Crowe's performance as John Nash is simply brilliant, and the film's exploration of Nash's\n",
        "                   genius and struggle with schizophrenia is both engaging and heartbreaking. Overall,\n",
        "                   'A Beautiful Mind' is a deeply moving and inspiring film that offers a powerful message of hope and resilience.'''\n",
        "\n",
        "review_text = [review_text]\n",
        "review_text_preprocessed = bert_textvect(review_text)\n",
        "features_review_text = bert_features(review_text_preprocessed)\n",
        "model.predict(features_review_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB__2aaX8lYQ",
        "outputId": "1b35d446-d966-4906-fd6b-edbf9ec82e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]]\n"
          ]
        }
      ],
      "source": [
        "print(y_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
