{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ],
      "metadata": {
        "id": "HfYu-Hk0R8PO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5kWWfR8z9uZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# initialize the seeds of different random number generators so that the \n",
        "# results will be the same every time the notebook is run\n",
        "keras.utils.set_random_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWOYqBF03aBE"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "Your goal in this exercise is to detect emotion from a facial image. To that end, we will use the 2013 Facial Expression Recognition (FER) dataset. \n",
        "\n",
        "The dataset consists of ~36,000 images, each annotated with one of seven labels:\n",
        "* angry\n",
        "* disgust\n",
        "* fear\n",
        "* happy\n",
        "* sad\n",
        "* surprise\n",
        "* neutral \n",
        "\n",
        "We will do two things:\n",
        "\n",
        "1) Build a Convolutional Neural Network (CNN) *from scratch* to detect emotion in facial images.  \n",
        "2) Use transfer learning to customize a pretrained model to solve the same problem. \n",
        "\n",
        "But first, let's get the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -P ./ https://www.dropbox.com/s/ia62dg6kpp3q8wb/fer2013.csv"
      ],
      "metadata": {
        "id": "kklgssFnY8Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5S29hLu7djK"
      },
      "source": [
        "data = pd.read_csv('/content/fer2013.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "Y5LyaciGpask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "tqK3tOTrpgZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.loc[0,'pixels'])"
      ],
      "metadata": {
        "id": "xXzpgKdkp2SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pixel values for each image is provided as a space-separated list of numbers. How many pixels in an image?"
      ],
      "metadata": {
        "id": "jmam5zVrqLnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data.loc[0, 'pixels'].split(' '))"
      ],
      "metadata": {
        "id": "bB5sxzlcqekw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtEmyeIL7o9V"
      },
      "source": [
        "So each (gray-scale) image is encoded as a list of 2304 pixels. We will reshape this into an 48x48 image next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG4mAu4k-k86"
      },
      "source": [
        "pixels = data['pixels'].tolist()\n",
        "width, height = 48, 48\n",
        "faces = []\n",
        "for pixel_sequence in pixels:\n",
        "    face = [int(pixel) for pixel in pixel_sequence.split(' ')] # read each face as a 1-d array \n",
        "    face = np.asarray(face).reshape(width, height) # reshape the length 2304 1-d array into an 48x48 array\n",
        "    face = np.stack((face,)*3, axis=-1) # convert single channel to three channels simply by replicating the single channel we have. \n",
        "    faces.append(face.astype('float32'))\n",
        "faces = np.asarray(faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's take a look at how emotion is encoded."
      ],
      "metadata": {
        "id": "T3rDhcpVrIVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.emotion.unique()"
      ],
      "metadata": {
        "id": "fMRxvh9grOBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, so it is sparse encoded.\n",
        "\n",
        "Just for practice, we will change the sparse coding to one-hot encoding."
      ],
      "metadata": {
        "id": "xZb-BpG6rjpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = pd.get_dummies(data['emotion']).to_numpy() # each emotion is 'one-hot' encoded as a 7-dim vector\n",
        "emotions_names = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral') "
      ],
      "metadata": {
        "id": "2O9Mj_fkrGig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WZRh-dDBvWw"
      },
      "source": [
        "Lets take a look at some of these fun images! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqmEpir1B3Mu"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = fig.add_subplot(3, 3, i+1)\n",
        "    ax.set_title(f\"{emotions_names[np.argmax(emotions[i])]}\")\n",
        "    ax.imshow(faces[i].astype('uint8'))\n",
        "    ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sts35VbQGJMf"
      },
      "source": [
        "As in the original dataset, we will reserve the first 28,709 images for training and the rest for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8sgM1kptNb"
      },
      "source": [
        "train_faces, train_emotions =  faces[:28709], emotions[:28709]\n",
        "test_faces, test_emotions =  faces[28709:], emotions[28709:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_faces.shape, train_emotions.shape)"
      ],
      "metadata": {
        "id": "Rs8BTG252Oh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_faces.shape, test_emotions.shape)"
      ],
      "metadata": {
        "id": "kr2jXspqqs7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1\n",
        "\n",
        "We will try a simple CNN on this dataset with three convolutional blocks + one dense layer + output layer."
      ],
      "metadata": {
        "id": "-aQhn5et0LoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.Input(shape=train_faces.shape[1:])\n",
        "x = keras.layers.Rescaling(1./255)(input) #normalizing\n",
        "x = keras.layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_1\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_3\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(256, activation=\"relu\")(x)   \n",
        "output = keras.layers.Dense(7, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "model = keras.Model(input, output, name='CNN_model')"
      ],
      "metadata": {
        "id": "dJD-ejmW0naX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "oQ9uJx7YtU4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23784fe-235c-4ad2-c4b0-80b2e4f0fd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CNN_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 48, 48, 3)         0         \n",
            "                                                                 \n",
            " Conv_1 (Conv2D)             (None, 47, 47, 16)        208       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_2 (Conv2D)             (None, 22, 22, 16)        1040      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " Conv_3 (Conv2D)             (None, 10, 10, 16)        1040      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               102656    \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 106,743\n",
            "Trainable params: 106,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yHAHKo0W1fym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we one-hot-encoded the dependent variable, we use `categorical_crossentropy`, not `sparse_categorical_crossentropy`.👆."
      ],
      "metadata": {
        "id": "MDj8v1-0sPmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "history = model.fit(train_faces, train_emotions, \n",
        "          batch_size=64, \n",
        "          epochs=epochs, \n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "tGd1oX0N1kfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8YHzLOsNuwbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the test accuracy?"
      ],
      "metadata": {
        "id": "JMHLB8_fuDbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code below and execute this cell\n"
      ],
      "metadata": {
        "id": "Q2S3SGwF1bXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2\n",
        "\n",
        "Add an additional dense layer to the CNN from Problem 1."
      ],
      "metadata": {
        "id": "JAG5qQ7WXco0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.Input(shape=train_faces.shape[1:])\n",
        "x = keras.layers.Rescaling(1./255)(input) #normalizing\n",
        "x = keras.layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_1\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_3\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Flatten()(x)\n",
        "\n",
        "#################################################################\n",
        "### ADD A DENSE LAYER WITH 256 RELU NEURONS IN THE LINE BELOW ###\n",
        "\n",
        "#################################################################\n",
        "\n",
        "x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "output = keras.layers.Dense(7, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "model2 = keras.Model(input, output, name='CNN_model2')"
      ],
      "metadata": {
        "id": "TzU_AhECXvfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "id": "3zv2MDgbXya2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "66cEA3fDYKGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "history = model2.fit(train_faces, train_emotions, \n",
        "          batch_size=64, \n",
        "          epochs=epochs, \n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "0httpbJ7YMDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "slcAgF-FYSfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the test accuracy?"
      ],
      "metadata": {
        "id": "MxrVICYM_Z9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code below and execute this cell\n"
      ],
      "metadata": {
        "id": "NSE66SFUYQek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3"
      ],
      "metadata": {
        "id": "UIGCf1_zA5G1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C4PGf4X1Ib5"
      },
      "source": [
        "***Data Augmentation:*** \n",
        "\n",
        "The basic idea of augmentation is to alter the image so slightly that the value of the dependent variable (i.e. the category that it belongs to) doesn't change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18vDhSv6RWK"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.RandomFlip(\"horizontal\"),\n",
        "        keras.layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ehLSXqP1b5P"
      },
      "source": [
        "Lets quickly visualize what the augmentation does ... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTDMmESZ6TZ_"
      },
      "source": [
        "augmented_images = [data_augmentation(np.expand_dims(train_faces[0],axis=0)) for i in range(9)]\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = fig.add_subplot(3, 3, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(tf.keras.preprocessing.image.array_to_img(augmented_images[i][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.Input(shape=train_faces.shape[1:])\n",
        "\n",
        "x = data_augmentation(input)  \n",
        "\n",
        "x = keras.layers.Rescaling(1./255)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_1\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_3\")(x) # convolutional layer!\n",
        "x = keras.layers.MaxPool2D()(x) # pooling layer\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(512, activation=\"relu\")(x)   \n",
        "output = keras.layers.Dense(7, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(input, output, name='augmented_CNN_model')"
      ],
      "metadata": {
        "id": "9Yk6UhMrBSVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "oFDrN4GfBiRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mJCy1tCyBhxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "history = model.fit(train_faces, train_emotions, \n",
        "          batch_size=64, \n",
        "          epochs=epochs, \n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "PMW5t9ZOBlyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xhXMussbBqTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's the test accuracy?"
      ],
      "metadata": {
        "id": "Kr59BH9EJPLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code below and execute this cell\n"
      ],
      "metadata": {
        "id": "2narK55FJTXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ddqer_8KbwB"
      },
      "source": [
        "# Problem 4\n",
        "\n",
        "Next, we apply transfer learning to our problem. We will take a slightly different approach from what we saw in class: instead of running each image through a pre-trained \"headless\" model to get smart representations and then using them as the input to our own \"little\" NN, we will do the following: we will (a) remove the top from an existing pre-trained model to get a \"headless\" model (b) \"attach\" our little NN to to this \"headless\" model and (c) train this **entire** model. \n",
        "\n",
        "\n",
        "Why? So that we can 'fine-tune' the weights of the original pre-trained model (along with the weights of our \"little\" NN) to better minimize our loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHKqB9r1iH9W"
      },
      "source": [
        "***Overall Approach*** \n",
        "\n",
        "In class, we used ResNet50. In this problem, we will use another pretrained model called [VGG19](https://keras.io/api/applications/vgg/).\n",
        " \n",
        "\n",
        "1.   We will remove the top of VGG19 to make it \"headless\". We will refer to this as the \"base model\".\n",
        "2.   We will create a little NN and connect the output of the base model to this little NN.\n",
        "3. ** We will unfreeze the last 10 layers of the base model so that SGD/Adam can optimize those weights as well.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYOu-5lMPZRX"
      },
      "source": [
        "# We will define a function that will build a model per the approach above\n",
        "\n",
        "def construct_model(no_classes, input_shape, metrics=['accuracy']):\n",
        "\n",
        "  base_model = keras.applications.VGG19(\n",
        "    include_top=False,   # this makes VGG19 headless\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        "  )\n",
        "\n",
        "  # Freeze the base_model\n",
        "  base_model.trainable = False\n",
        "\n",
        "  \n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "  x = keras.layers.Rescaling(1./255)(inputs) #normalizing\n",
        "\n",
        "  # Apply random data augmentation\n",
        "  x = data_augmentation(x)  \n",
        "\n",
        "  # The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "  # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "  # base_model is running in inference mode here. We didn't cover batchnorm \n",
        "  # layers in class so just take our word for it :-)\n",
        "  x = base_model(x, training=False)\n",
        "  \n",
        "  # Next we connect the output from our headless model to our little NN\n",
        "  # we will flatten the output of the headless\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "  outputs = keras.layers.Dense(no_classes, activation='softmax')(x)\n",
        "  \n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.summary()\n",
        "\n",
        "  # unfreeze the last 10 layers of the model so that we can \n",
        "  # optimize the weights of those layers (along with the weights\n",
        "  # of the layers of the little NN)\n",
        "\n",
        "  for layer in model.layers[-10:]:\n",
        "      if not isinstance(layer, keras.layers.BatchNormalization): #the batch normalization layer is untouched \n",
        "          layer.trainable = True\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', \n",
        "                optimizer=keras.optimizers.Adam(0.2*1e-4), #here we choose a different rate for Adam than default for better convergence\n",
        "                metrics=metrics) \n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OlMcWW6ji1Z"
      },
      "source": [
        "***Training the Overall Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Ahpg7vQ519"
      },
      "source": [
        "no_classes = 7\n",
        "NUM_EPOCHS = 30\n",
        "model = construct_model(no_classes,(48,48,3))\n",
        "\n",
        "history = model.fit(train_faces, train_emotions, epochs=NUM_EPOCHS, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "acc = history_dict[\"accuracy\"]\n",
        "val_acc = history_dict[\"val_accuracy\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_XWZv3tCeKWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calc the accuracy on the test set."
      ],
      "metadata": {
        "id": "XV9GdokoMPd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your code below and execute this cell\n"
      ],
      "metadata": {
        "id": "mzg5PNAf1BiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy for the testing set has improved significantly. Note, however, that the state-of-the-art for this dataset is around 73.3%."
      ],
      "metadata": {
        "id": "Trh8XLTcXnlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's calculate the confusion matrix."
      ],
      "metadata": {
        "id": "yYkyOqTgl2oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_index = model.predict(test_faces).argmax(axis=1)\n",
        "actuals_index = test_emotions.argmax(axis=1)\n",
        "\n",
        "actuals = [emotions_names[i] for i in actuals_index]\n",
        "predictions = [emotions_names[i] for i in predictions_index]\n"
      ],
      "metadata": {
        "id": "z1W3a8u68GVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c5d403-792f-49de-f8b4-1c6137b5f4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 3s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'Predictions': predictions, 'Actuals': actuals})\n",
        "a=pd.crosstab(df.Predictions, df.Actuals)\n",
        "a"
      ],
      "metadata": {
        "id": "1aHxeB2w85LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To help with interpretability, we can plot a heatmap of the confusion matrix as well."
      ],
      "metadata": {
        "id": "_0TjDGSyKLIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np; np.random.seed(0)\n",
        "import seaborn as sns; sns.set_theme()\n",
        "\n",
        "ax = sns.heatmap(a)"
      ],
      "metadata": {
        "id": "RdOh8GZIKEjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvHLqygkSlLA"
      },
      "source": [
        "# Problem 5\n",
        "It is now your turn. \n",
        "\n",
        "Take the code for Problem 4 and modify it so that it uses ResNet50 as the base model and not VGG19. Answer the questions in the Homework document."
      ]
    }
  ]
}